#!/usr/bin/python
"""Phoenix power control"""
# vim: tabstop=4 shiftwidth=4 softtabstop=4

import sys
import signal
import argparse
import logging
from ClusterShell.NodeSet import NodeSet, set_std_group_resolver_config
from ClusterShell.Task import task_self, Task
from ClusterShell.CLI.Config import ClushConfig, ClushConfigError
from ClusterShell.CLI.Error import GENERIC_ERRORS, handle_generic_error
from ClusterShell.CLI.Display import Display, sys_stdin

import phoenix
from phoenix.Node import Node

import concurrent.futures
import requests
#only need os and inspect for debugging, and time
import os
import inspect
import time

# This is needed to turn off SSL warnings
from requests.packages.urllib3.exceptions import InsecureRequestWarning
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)


#when we sigint a phoenix command, find all clustershell tasks and abort them
#We might only be able to abort tasks in the local frame, unfortunately
def phoenix_clustershell_cleanup(signal_int, frame):
  logger.debug('sigint caught, starting cleanup!')

  #print inspect.getmembers(frame)
  #this is potentially expensive, but I can't think of a better way atm
  for object_name, local_object in frame.f_locals.items():
    if isinstance(local_object, Task):
      logger.debug("Aborting a clustershell task.")
      local_object.abort()

  sys.exit(-1)


#this needs called by anything that is using clustershell
#otherwise, we risk hanging the shell
def phoenix_int_handler():
  signal.signal(signal.SIGINT, phoenix_clustershell_cleanup)

#psutil is not easy to get for suse 12 without internet...
##kill all futures then sigint to clean up clustershell threads with phoenix_clustershell_cleanup, if there are any
#def phoenix_terminate_all(pid, future_executor):
#
#  future_executor.shutdown(wait=False)
#
#  try:
#    parent = psutil.Process(pid)
#  except psutil.NoSuchProcess:
#    print "We should never be here."
#    return
#  children = parent.children(recursive=True) #just in case threads called threads
#  for process in children:
#    process.send_signal(signal.SIGINT)


def get_parser():
  parser = argparse.ArgumentParser(prog="phoenix_power", description="Control the power of Phoenix nodes")
  parser.add_argument('nodes', help='Nodes to control', type=str)
  parser.add_argument('state', help='Desired state', type=str)
  parser.add_argument('--cs', '--clustershell_arg', help='Optional Clustershell args.', type=str)
  parser.add_argument('-v', '--verbose', action='count', default=0)
  parser.add_argument('-w', '--worker', action='count', default=0)
  return parser


def _do_req(node, state):
  try:
    nodeobj = Node.find_node(node)
  except KeyError:
    logging.error("Could not find node '%s'", node)
    return "%s: %s" % (node, 'UnknownNode')

  # Normalize the requested state
  state = state.lower()

  redfishbaseurl = "https://%s/redfish/v1/Systems/%s" % (nodeobj['bmc'], nodeobj['redfishpath'])

  # XXX TODO Pull this from Phoenix
  auth = ('root', 'initial0')

  #have requests operate on whether or not you have certain fields

  if state in ['stat', 'state', 'status']:
      logging.debug("redfishbaseurl: {0}".format(redfishbaseurl))
    try:
      response = requests.get(redfishbaseurl, verify=False, auth=auth, timeout=10)
      rjson = response.json()
      return "%s: %s" % (node, rjson['PowerState'])
    except:
      return "{0}: Unknown,Timeout".format(node)
  elif state in ['on']:
    data = { 'ResetType': 'On' }
    headers = { 'Content-Type': 'application/json' }

    url = "%s/%s" % (redfishbaseurl, 'Actions/ComputerSystem.Reset')
    response = requests.post(url, verify=False, auth=auth, headers=headers, json=data, timeout=10)
  elif state in ['off']:
    data = { 'ResetType': 'ForceOff' }
    headers = { 'Content-Type': 'application/json' }

    url = "%s/%s" % (redfishbaseurl, 'Actions/ComputerSystem.Reset')
    response = requests.post(url, verify=False, auth=auth, headers=headers, json=data, timeout=10)
  elif state in ['reset', 'restart']:
    #Since this isn't implemented in some bmcs, do we want to force off then force on?
    data = { 'ResetType': 'ForceRestart' }
    headers = { 'Content-Type': 'application/json' }

    url = "%s/%s" % (redfishbaseurl, 'Actions/ComputerSystem.Reset')
    response = requests.post(url, verify=False, auth=auth, headers=headers, json=data, timeout=10)
  else:
    return "%s Invalid Node State, ie. On, Off, Restart, Status" % (node)

    # Current NCs are returning a 204 - need to test if this makes sense
    # Also figure out what an error response looks like and return it
  if response.status_code == 200 or response.status_code == 204:
    return "%s: Ok" % node
  else:
    return "%s: Failed - status %d" % (node, response.status_code)


#there is nothing power specific in the following def
def run_clustershell_command(command, cs_ns, arguments=[]):
  #output of other commands will be passed up to you, you must pass it along

  #TODO: How do we tell whether we need to call the worker or if we have another layer of hierarchy to go through?
  #I think clustershell will take care of this for us, so we will just blindly assume we are popping out on the other side as a worker

  #"%hosts" is that magic thing that makes clustershell not spawn a thread/process for every node
  arguments = " ".join([",".join(cs_ns), ",".join(arguments), " --worker --cs %hosts"])
  #print "arguments: " + arguments

  task = Task()
  task.set_info("connect_timeout", 65) #I'm not sure this works
  task.set_info("command_timeout", 65) #I'm not sure this works
  ##TODO: acquire fanout from settings or args
  #task.set_info("fanout", 128)
  #task.set_default("stdout_msgtree", False) #this just turns off output?

  logging.debug("Command + Arguments: {0} {0}".format(command, arguments))
  shell_line = "%s %s" % (command, arguments)
  task.shell(shell_line, nodes=cs_ns, remote=False, autoclose="enable_autoclose")
  task.run()
  task.join()

  #get output
  for output, cs_ns in task.iter_buffers():
    print '%s: %s' % (cs_ns, output)

  #It's probably safest to abort only after we've acquired all output from above
  task.abort()


#a function that gets called by run_threaded_command must accept a list of args and a list of nodes
#TODO: have power call _do_req, and have _do_req be generic for all redfish requests
def power(node, arglist=[]):
  """
  POWWWAAAAAHH
  https://media0.giphy.com/media/Ixx5oJTLtmrgQ/giphy.gif
  """
  state = arglist[0] #the only arg is state
  logging.debug("state: {0}".format(state))
  rc = _do_req(node, state)

  return rc


#runs threaded commands on a service node
def run_local_threaded_command(function, cs_ns, arglist=[]):
  """
  Function is the function that we will parallelize.
  arglist is a list of arguments for the function.
  cs_ns is a hostlist of all nodes that we will run the function against.
  """

  rc = 0
  Node.load_nodes(nodeset=cs_ns)

  timeout = 60 #this is the futures timeout. We want requests to timeout first, than futures, then clustershell.
  threads = len(cs_ns)
  executor = concurrent.futures.ThreadPoolExecutor(max_workers = threads, thread_name_prefix='clustershell_phoenix_worker')

  futurelist = []
  for node in cs_ns:
    futurelist.append(executor.submit(function, node, arglist))

  try:
    for future in concurrent.futures.as_completed(futurelist, timeout=timeout):
      try:
        data = future.result()
      except Exception as exc:
        print "Error: %s" % exc
      else:
        print data
  except concurrent.futures.TimeoutError:
    print "Timeout on a node.".format(node)
    rc = rc + 1
    #we can't kill these things without waiting for them :(
    ##catching the exception will end the loop anyway, so let's end it all
    #phoenix_terminate_all(os.getpid(), executor)
  return rc


if __name__ == '__main__':
  phoenix_int_handler()
  set_std_group_resolver_config('/etc/clustershell/groups.conf.d/phoenix.conf')
  parser = get_parser()
  args = parser.parse_args()
  phoenix.setup_logging(args.verbose)

  arguments = [args.state]
  #print arguments

  #TODO: We need to create a display so we can undo that nasty summarizing stuff.
  #the code should probably go in the clustershell call area
  #print display.line_mode
  #exit(1)

  nodelist = args.nodes.split(",")
  cs_ns = NodeSet.fromlist(nodelist)

  #for i in cs_ns:
  #  print i

  if args.worker == 0:
    logging.debug("We are the hierarchy caller")
    #we are being called to orchestrate a clustershell call
    #run_clustershell_command("/home/muzyncj/phoenix/bin/phoenix_power", cs_ns, arguments)
    run_clustershell_command("phoenix_power", cs_ns, arguments)
  elif args.worker == 1:
    logging.debug("We are the worker")
    #we are being called to do real work
    #TODO: change to power, _do_req will become generic
    rc = run_local_threaded_command(power, cs_ns, arguments)
    if rc > 0:
      print "We timed out on {0} node(s).".format(rc)

  rc = 0

  sys.exit(rc)
