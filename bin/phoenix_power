#!/usr/bin/python
"""Phoenix power control"""
# vim: tabstop=4 shiftwidth=4 softtabstop=4

import sys
import signal
import argparse
import logging
from ClusterShell.NodeSet import NodeSet, set_std_group_resolver_config
from ClusterShell.Task import task_self, Task
from ClusterShell.CLI.Config import ClushConfig, ClushConfigError
from ClusterShell.CLI.Error import GENERIC_ERRORS, handle_generic_error

import phoenix
from phoenix.Node import Node

import concurrent.futures
import requests
#only need os and inspect for debugging
import os
import inspect

# This is needed to turn off SSL warnings
from requests.packages.urllib3.exceptions import InsecureRequestWarning
requests.packages.urllib3.disable_warnings(InsecureRequestWarning)

#when we sigint a phoenix command, find all clustershell tasks and abort them
#We might only be able to abort tasks in the local frame, unfortunately
def phoenix_clustershell_cleanup(signal, frame):
  print 'sigint caught, starting cleanup!'

  #this is potentially expensive, but I can't think of a better way atm
  for object_name, local_object in frame.f_locals.items():
    if isinstance(local_object, Task):
      print "Aborting a clustershell task."  #debug
      local_object.abort()

  sys.exit(-1)

def phoenix_int_handler():
  signal.signal(signal.SIGINT, phoenix_clustershell_cleanup)

def get_parser():
  parser = argparse.ArgumentParser(prog="phoenix_power", description="Control the power of Phoenix nodes")
  parser.add_argument('nodes', help='Nodes to control')
  parser.add_argument('state', help='Desired state')
  parser.add_argument('-v', '--verbose', action='count', default=0)
  parser.add_argument('-w', '--worker', action='count', default=0)
  return parser

def _do_req(node, state):
  try:
    nodeobj = Node.find_node(node)
  except KeyError:
    logging.error("Could not find node '%s'", node)
    return "%s: %s" % (node, 'UnknownNode')

  # Normalize the requested state
  state = state.lower()

  redfishbaseurl = "https://%s/redfish/v1/Systems/%s" % (nodeobj['bmc'], nodeobj['redfishpath'])

  # XXX TODO Pull this from Phoenix
  auth = ('root', 'initial0')

  if state in ['stat', 'state', 'status']:
    response = requests.get(redfishbaseurl, verify=False, auth=auth)
    rjson = response.json()
    return "%s: %s" % (node, rjson['PowerState'])
  elif state in ['on']:
    data = { 'ResetType': 'On' }
    headers = { 'Content-Type': 'application/json' }

    url = "%s/%s" % (redfishbaseurl, 'Actions/ComputerSystem.Reset')
    response = requests.post(url, verify=False, auth=auth, headers=headers, json=data)

    # Current NCs are returning a 204 - need to test if this makes sense
    # Also figure out what an error response looks like and return it
    if response.status_code == 200 or response.status_code == 204:
      return "%s: Ok" % node
    else:
      return "%s: Failed - status %d" % (node, response.status_code)

#clustershell does this on its own "in a dshbak way" whatever that means
#def summarize_output:

#there is nothing power specific in the following def
def run_clustershell_command(command, arguments, cs_hostlist, output="summarize"):
  #output of other commands will be passed up to you, you must pass it along

  #TODO: How do we tell whether we need to call the worker or if we have another layer of hierarchy to go through?
  #I think clustershell will take care of this for us, so we will just blindly assume we are popping out on the other side as a worker
  arguments = " ".join([arguments, cs_hostlist, " --worker"])

  ns_obj = NodeSet(cs_hostlist)

  task = Task()
  task.set_info("connect_timeout", 10)
  task.set_info("command_timeout", 10)
  ##TODO: acquire fanout from settings or args
  #task.set_info("fanout", 128)
  print "Command + Arguments: " + command + " " + arguments
  shell_line = "%s %s" % (command, arguments)
  task.shell(shell_line, nodes=ns_obj, remote=False)
  task.run()
  task.join()

  #get output
  for output, cs_hostlist in task.iter_buffers():
    print '%s: %s' % (ns_obj, output)

  #It's probably safest to abort only after we've acquired all output from above
  task.abort()

#runs threaded commands on a service node
def run_local_threaded_command(function, cs_nodelist, arglist=[]):
  """
  Function is the function that we will parallelize.
  arglist is a list of arguments for the function.
  cs_hostlist is a hostlist of all nodes that we will run the function against.
  """
  rc = 0
  #mynodes = NodeSet.fromlist([cs_nodelist])
  #Node.load_nodes(nodeset=mynodes)

  timeout = 10
  threads = len(cs_nodelist)

  executor = concurrent.futures.ThreadPoolExecutor(max_workers = threads, thread_name_prefix='clustershell_phoenix_worker')

  futurelist = []
  for node in cs_nodelist:
    futurelist.append(executor.submit(function, node, arglist))

  try:
    for future in concurrent.futures.as_completed(futurelist, timeout=timeout):
      try:
        data = future.result()
      except Exception as exc:
        print "Error: %s" % exc
      else:
        print data
  except concurrent.futures.TimeoutError:
    print "Timeout"
    rc = rc + 1

  return rc



#a function that gets called by run_threaded_command must accept a list of args and a list of nodes
#TODO: have power call _do_req, and have _do_req be generic for all redfish requests
def power(node, arglist=[]):
  """
  POWWWAAAAAHH
  https://media0.giphy.com/media/Ixx5oJTLtmrgQ/giphy.gif
  """
  state = arglist[0] #the only arg is state
  return _do_req(node, state)



if __name__ == '__main__':

  phoenix_int_handler()
  set_std_group_resolver_config('/etc/clustershell/groups.conf.d/phoenix.conf')
  parser = get_parser()
  args = parser.parse_args()
  phoenix.setup_logging(args.verbose)

  if args.worker == 0:
    print "We are the hierarchy caller"
    #we are being called to orchestrate a clustershell call
    #args_list = args.state
    run_clustershell_command("/usr/bin/phoenix_power", args.state, args.nodes)
  elif args.worker == 1:
    print "We are the worker"
    #we are being called to do real work
    #TODO: change to power, _do_req will become generic
    run_local_threaded_command(_do_req, [args.state], args.nodes)

  rc = 0

  sys.exit(rc)
